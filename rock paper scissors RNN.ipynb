{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Example hyperparameters\n",
    "hidden_size = 24  # Increase hidden size\n",
    "learning_rate = 0.5   # Adjust learning rate\n",
    "num_layers = 2  # Increase number of layers\n",
    "dropout_rate = 0  # Implement dropout to prevent overfitting\n",
    "weight_decay = 1e-5\n",
    "\n",
    "# Define the RNN model with the new hyperparameters\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "# Updated RPSRNN class to move model to the appropriate device\n",
    "class RPSRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1, dropout=0):\n",
    "        super(RPSRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, dropout=dropout, batch_first=True).to(device)\n",
    "        self.i2o = nn.Linear(hidden_size, output_size).to(device)\n",
    "        self.softmax = nn.LogSoftmax(dim=1).to(device)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        input = input.to(device)\n",
    "        hidden = hidden.to(device)\n",
    "        output, hidden = self.rnn(input, hidden)\n",
    "        output = self.i2o(output[:, -1, :])  # We take the output from the last timestep\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        # Initialize the hidden state with the correct dimensions\n",
    "        return torch.zeros(self.num_layers, 1, self.hidden_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize multiple RNNs with different window sizes\n",
    "window_sizes = [3, 5, 10, 20, 50, 100]\n",
    "rnns = {window_size: RPSRNN(input_size=3, hidden_size=hidden_size, output_size=3, num_layers=num_layers, dropout=dropout_rate) for window_size in window_sizes}\n",
    "optimizers = {window_size: optim.SGD(rnn.parameters(), lr=learning_rate, weight_decay=weight_decay) for window_size, rnn in rnns.items()}\n",
    "accuracies = {window_size: 0 for window_size in window_sizes}  # Tracking accuracies\n",
    "correct_predictions = {window_size: 0 for window_size in window_sizes}  # Correct predictions count\n",
    "total_predictions = {window_size: 0 for window_size in window_sizes}  # Total predictions count\n",
    "\n",
    "# Other global variables\n",
    "hidden = {window_size: rnn.initHidden() for window_size, rnn in rnns.items()}\n",
    "previous_moves = []  # Keep track of the player's previous moves\n",
    "total_matches = 0\n",
    "wins = 0\n",
    "losses = 0\n",
    "draws = 0\n",
    "\n",
    "# Create buttons with cyan color\n",
    "button_rock = widgets.Button(description=\"Rock\", style={'button_color': 'cyan'})\n",
    "button_paper = widgets.Button(description=\"Paper\", style={'button_color': 'cyan'})\n",
    "button_scissors = widgets.Button(description=\"Scissors\", style={'button_color': 'cyan'})\n",
    "output = widgets.Output()\n",
    "\n",
    "# Mapping of winning moves\n",
    "winning_move = {\n",
    "    \"rock\": \"paper\",\n",
    "    \"paper\": \"scissors\",\n",
    "    \"scissors\": \"rock\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert moves to tensors\n",
    "def move_to_tensor(move):\n",
    "    if move == \"rock\":\n",
    "        return torch.tensor([1, 0, 0], dtype=torch.float).view(1, -1)\n",
    "    elif move == \"paper\":\n",
    "        return torch.tensor([0, 1, 0], dtype=torch.float).view(1, -1)\n",
    "    elif move == \"scissors\":\n",
    "        return torch.tensor([0, 0, 1], dtype=torch.float).view(1, -1)\n",
    "\n",
    "def tensor_to_move(tensor):\n",
    "    _, index = tensor.topk(1)\n",
    "    move = [\"rock\", \"paper\", \"scissors\"][index.item()]\n",
    "    return move\n",
    "\n",
    "# Game logic to determine the winner\n",
    "def get_winner(player_move, ai_move):\n",
    "    if player_move == ai_move:\n",
    "        return \"It's a tie!\"\n",
    "    elif (player_move == \"rock\" and ai_move == \"scissors\") or \\\n",
    "         (player_move == \"paper\" and ai_move == \"rock\") or \\\n",
    "         (player_move == \"scissors\" and ai_move == \"paper\"):\n",
    "        return \"You win!\"\n",
    "    else:\n",
    "        return \"AI wins!\"\n",
    "\n",
    "# Training function for each RNN\n",
    "def train_rnn(rnn, optimizer, move_sequence, player_move):\n",
    "    rnn.train()  # Ensure the model is in training mode\n",
    "    hidden_state = rnn.initHidden()\n",
    "    target_tensor = torch.tensor([[\"rock\", \"paper\", \"scissors\"].index(player_move)], dtype=torch.long).to(device)\n",
    "    \n",
    "    for move in move_sequence:\n",
    "        move_tensor = move_to_tensor(move).view(1, 1, -1).to(device)  # Move input to the correct device\n",
    "        output, hidden_state = rnn(move_tensor, hidden_state)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss = nn.NLLLoss()(output, target_tensor)\n",
    "    loss.backward()\n",
    "    \n",
    "    # Clip gradients to prevent exploding gradients\n",
    "    torch.nn.utils.clip_grad_norm_(rnn.parameters(), max_norm=1.0)\n",
    "    \n",
    "    optimizer.step()\n",
    "\n",
    "# Update the accuracy of each RNN\n",
    "def update_accuracies(predicted_move, actual_move, window_size):\n",
    "    total_predictions[window_size] += 1\n",
    "    if predicted_move == actual_move:\n",
    "        correct_predictions[window_size] += 1\n",
    "    #print(f\"Window size: {window_size}, Correct: {correct_predictions[window_size]}, Total: {total_predictions[window_size]}\")\n",
    "    accuracies[window_size] = correct_predictions[window_size] / total_predictions[window_size]\n",
    "\n",
    "# Predict with each RNN and return their predictions\n",
    "def predict_with_rnns(previous_moves):\n",
    "    predictions = {}\n",
    "    \n",
    "    for window_size, rnn in rnns.items():\n",
    "        if len(previous_moves) >= window_size:\n",
    "            move_sequence = previous_moves[-window_size:]\n",
    "            hidden_state = rnn.initHidden()\n",
    "            \n",
    "            rnn.eval()  # Set model to evaluation mode\n",
    "            with torch.no_grad():  # No need to compute gradients during inference\n",
    "                for move in move_sequence:\n",
    "                    move_tensor = move_to_tensor(move).view(1, 1, -1).to(device)  # Move input to the correct device\n",
    "                    output, hidden_state = rnn(move_tensor, hidden_state)\n",
    "                \n",
    "            predicted_move = tensor_to_move(output)\n",
    "            predictions[window_size] = predicted_move\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Weighted voting based on RNN accuracies\n",
    "def weighted_vote(predictions):\n",
    "    vote_counts = {\"rock\": 0, \"paper\": 0, \"scissors\": 0}\n",
    "    \n",
    "    for window_size, prediction in predictions.items():\n",
    "        weight = accuracies[window_size] + 0.1  # Add a small constant to avoid zero weights\n",
    "        vote_counts[prediction] += weight\n",
    "    \n",
    "    return max(vote_counts, key=vote_counts.get)\n",
    "\n",
    "def process_ai_move(previous_moves, player_move, rnns, optimizers, winning_move):\n",
    "    if len(previous_moves) > 0:\n",
    "        predictions = predict_with_rnns(previous_moves)\n",
    "        \n",
    "        # Predict the player's next move based on the RNNs\n",
    "        predicted_player_move = weighted_vote(predictions)  \n",
    "        ai_move = winning_move[predicted_player_move]  # AI chooses the move that beats the predicted move\n",
    "        \n",
    "        # Update RNNs and their accuracies\n",
    "        for window_size, rnn in rnns.items():\n",
    "            if len(previous_moves) >= window_size:\n",
    "                move_sequence = previous_moves[-window_size:]\n",
    "                train_rnn(rnn, optimizers[window_size], move_sequence, player_move)\n",
    "                update_accuracies(predictions[window_size], player_move, window_size)\n",
    "    else:\n",
    "        ai_move = random.choice([\"rock\", \"paper\", \"scissors\"])\n",
    "    \n",
    "    return ai_move\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0499a46283714a1a9db3f856a7b70454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='Rock', style=ButtonStyle(button_color='cyan')), Button(description='Paper',â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27753c7cb7a047daa20a293572d3a54e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def on_button_click(b):\n",
    "    global wins; global losses; global draws; global total_matches\n",
    "    player_move = b.description.lower()\n",
    "    \n",
    "    with output:\n",
    "        clear_output()\n",
    "        \n",
    "        ai_move = process_ai_move(previous_moves, player_move, rnns, optimizers, winning_move)\n",
    "        \n",
    "        result = get_winner(player_move, ai_move)\n",
    "        \n",
    "        if result == \"AI wins!\":\n",
    "            losses += 1\n",
    "        elif result == \"You win!\":\n",
    "            wins += 1\n",
    "        else:\n",
    "            draws += 1\n",
    "\n",
    "        total_matches = losses + wins + draws\n",
    "        win_rate = (wins / total_matches) * 100 if total_matches > 0 else 0\n",
    "        wlr = wins/losses\n",
    "        print(f\"You chose: {player_move}\")\n",
    "        print(f\"AI chose: {ai_move}\")\n",
    "        print(result)\n",
    "        print(f\"\\nTotal Matches: {total_matches}\")\n",
    "        print(f\"Wins: {wins} | Losses: {losses} | Draws: {draws}\")\n",
    "        print(f\"Win Rate: {win_rate:.2f}%\")\n",
    "        print(f\"Win/Loss Rate: {wlr:.2f}\")\n",
    "    \n",
    "    previous_moves.append(player_move)\n",
    "\n",
    "\n",
    "\n",
    "# Bind buttons to the event handler and display\n",
    "button_rock.on_click(on_button_click)\n",
    "button_paper.on_click(on_button_click)\n",
    "button_scissors.on_click(on_button_click)\n",
    "display(widgets.HBox([button_rock, button_paper, button_scissors]), output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Possible moves\n",
    "moves = [\"rock\", \"paper\", \"scissors\"]\n",
    "\n",
    "# Function to generate a random move\n",
    "def random_move(move_sequence):\n",
    "    return random.choice(moves)\n",
    "\n",
    "def silly_strategy(move_sequence):\n",
    "    if len(move_sequence) == 0:\n",
    "        return random.choice([\"rock\", \"paper\", \"scissors\"])  # Random move if it's the first round\n",
    "    \n",
    "    last_move = move_sequence[-1]\n",
    "    \n",
    "    if last_move == \"rock\":\n",
    "        return \"paper\"\n",
    "    elif last_move == \"paper\":\n",
    "        return \"scissors\"\n",
    "    elif last_move == \"scissors\":\n",
    "        return \"rock\"\n",
    "# Function to allow for a customizable strategy\n",
    "def human_move(move_sequence, strategy=random_move):\n",
    "    # strategy can be a function that takes move_sequence as input and returns a move\n",
    "    return strategy(move_sequence)\n",
    "\n",
    "# Function to simulate N matches between AI and the opponent\n",
    "def simulate_matches(N, opponent_strategy=silly_strategy):\n",
    "    previous_moves = []\n",
    "    \n",
    "    ai_wins = 0\n",
    "    opponent_wins = 0\n",
    "    total_draws = 0\n",
    "    \n",
    "    for _ in tqdm(range(N)):\n",
    "        opponent_move = human_move(previous_moves, strategy=opponent_strategy)\n",
    "        \n",
    "        ai_move = process_ai_move(previous_moves, opponent_move, rnns, optimizers, winning_move)\n",
    "        \n",
    "        result = get_winner(opponent_move, ai_move)\n",
    "        \n",
    "        if result == \"AI wins!\":\n",
    "            ai_wins += 1\n",
    "        elif result == \"You win!\":\n",
    "            opponent_wins += 1\n",
    "        else:\n",
    "            total_draws += 1\n",
    "        \n",
    "        previous_moves.append(opponent_move)\n",
    "    \n",
    "    print(f\"After {N} matches:\")\n",
    "    print(f\"AI Wins: {ai_wins}\")\n",
    "    print(f\"Opponent Wins: {opponent_wins}\")\n",
    "    print(f\"Draws: {total_draws}\")\n",
    "    print(f\"AI Win Rate: {(ai_wins / N) * 100:.2f}%\")\n",
    "\n",
    "\n",
    "# Example usage: simulate 100 matches with a random opponent\n",
    "#simulate_matches(1000)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
